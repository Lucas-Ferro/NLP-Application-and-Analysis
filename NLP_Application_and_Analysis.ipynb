{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP - Application and Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4160d7d057c14991b649f8ffd7374156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0bd38723e9394e53a0e47ab8f6517cbd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_63a86d9e8e7244358706b61f344d2b2b",
              "IPY_MODEL_26d71011f3ce4ddcad0c67f170ea63c5",
              "IPY_MODEL_b5c4378040ee4028a3535f8e88661d6c"
            ]
          }
        },
        "0bd38723e9394e53a0e47ab8f6517cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63a86d9e8e7244358706b61f344d2b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7f4a0ee7af524b8ea8cbbd36656b980f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4020329a8d9493788e4263207d829e4"
          }
        },
        "26d71011f3ce4ddcad0c67f170ea63c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2317cf0a4b024f02a29591f59e1c5ca9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 24144,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 24144,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a627e58151d474cb6fef333f59464a2"
          }
        },
        "b5c4378040ee4028a3535f8e88661d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_365e43368fa247729d2476faaac745f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 140k/? [00:00&lt;00:00, 2.23MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13020ead645e4abe9c1e08bc33bd319c"
          }
        },
        "7f4a0ee7af524b8ea8cbbd36656b980f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4020329a8d9493788e4263207d829e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2317cf0a4b024f02a29591f59e1c5ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a627e58151d474cb6fef333f59464a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "365e43368fa247729d2476faaac745f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13020ead645e4abe9c1e08bc33bd319c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gt132CQCARq"
      },
      "source": [
        "<h1> NLP - Application and Analysis\n",
        "<h3> Author: Lucas Ferro Antunes de Oliveira\n",
        "<h4> HAILab - PPGTS - PUCPR\n",
        "\n",
        "<p> This notebook shows some applications of NLP models pursuing the construction of an annotated corpus. It also shows some normalization processes using Regex and post-analysis of the corpus.\n",
        "<p> Note: applications and analysis are made with the CoNLL-U format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNYZLjMBE7YO"
      },
      "source": [
        "---\n",
        "<h3> These cells install and import the libraries used throughout the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqUNS99bB8O7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9f6622-25b5-4ebc-fa42-89614b407778"
      },
      "source": [
        "# Install Libraries\n",
        "!pip install stanza\n",
        "!pip install spacy\n",
        "!pip install unidecode"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stanza in /usr/local/lib/python3.7/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.62.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.2.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.6.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhsFN22eB_dz"
      },
      "source": [
        "# Import Libraries\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "import unidecode\n",
        "import torch\n",
        "import stanza\n",
        "import spacy\n",
        "import time"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq-4rpaoD7qV"
      },
      "source": [
        "# Configure PATH to work directory\n",
        "# In google colab, we must create a folder under \"sample_data/\" called \"corpus\", for organization\n",
        "PATH = 'sample_data/corpus/'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BWzufJ0B_fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "4160d7d057c14991b649f8ffd7374156",
            "0bd38723e9394e53a0e47ab8f6517cbd",
            "63a86d9e8e7244358706b61f344d2b2b",
            "26d71011f3ce4ddcad0c67f170ea63c5",
            "b5c4378040ee4028a3535f8e88661d6c",
            "7f4a0ee7af524b8ea8cbbd36656b980f",
            "d4020329a8d9493788e4263207d829e4",
            "2317cf0a4b024f02a29591f59e1c5ca9",
            "7a627e58151d474cb6fef333f59464a2",
            "365e43368fa247729d2476faaac745f6",
            "13020ead645e4abe9c1e08bc33bd319c"
          ]
        },
        "outputId": "85fad817-c8bb-4b65-d96d-eb68e585924b"
      },
      "source": [
        "# Download NLP Models\n",
        "stanza.download('pt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4160d7d057c14991b649f8ffd7374156",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json:   0%|   …"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-16 12:42:27 INFO: Downloading default packages for language: pt (Portuguese)...\n",
            "2021-08-16 12:42:28 INFO: File exists: /root/stanza_resources/pt/default.zip.\n",
            "2021-08-16 12:42:31 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bETewpttFNce"
      },
      "source": [
        "---\n",
        "<h1> Parsing and Realizing text\n",
        "<h3> Next cells create the Parse and Realize functions\n",
        "<p> It contains every rule to parse and realize words in Portuguese, since capitalized words to uncapitalized words.\n",
        "\n",
        "<br> <p> Input type: string - usually a full sentence.\n",
        "<br> Output type: string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQwAYGB2B_hN"
      },
      "source": [
        "def parse(text):\n",
        "    text = re.sub(r'( )(cum)([ ,;!?.])', r'\\1 com um\\3', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'(Cum)([ ,;!?.])', r'Com um\\2', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'(CUM)([ ,;!?.])', r'COM UM\\2', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'( )(à)([ ,;!?.])', r'\\1a a\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(ao)([ ,;!?.])', r'\\1a o\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(às)([ ,;!?.])', r'\\1a as\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(aos)([ ,;!?.])', r'\\1a os\\3', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'(Ao)([ ,;!?.])', r'A o\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Aos)([ ,;!?.])', r'A os\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Às)([ ,;!?.])', r'A as\\2', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'( )(Ao)([ ,;!?.])', r'\\1A o\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(Às)([ ,;!?.])', r'\\1A as\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(Aos)([ ,;!?.])', r'\\1A os\\3', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'(À)([ ,;!?.])', r'A A\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(AO)([ ,;!?.])', r'A O\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(ÀS)([ ,;!?.])', r'A AS\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(AOS)([ ,;!?.])', r'A OS\\2', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'( )(À)([ ,;!?.])', r'\\1A A\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(AO)([ ,;!?.])', r'\\1A O\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(ÀS)([ ,;!?.])', r'\\1A AS\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(AOS)([ ,;!?.])', r'\\1A OS\\3', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'( )(do)([ ,;!?.])', r'\\1de o\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(da)([ ,;!?.])', r'\\1de a\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(dos)([ ,;!?.])', r'\\1de os\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(das)([ ,;!?.])', r'\\1de as\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(Do)([ ,;!?.])', r'\\1De o\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(Da)([ ,;!?.])', r'\\1De a\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(Dos)([ ,;!?.])', r'\\1De os\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(Das)([ ,;!?.])', r'\\1De as\\3', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'( )(DO)([ ,;!?.])', r'\\1DE O\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(DA)([ ,;!?.])', r'\\1DE A\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(DOS)([ ,;!?.])', r'\\1DE OS\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(DAS)([ ,;!?.])', r'\\1DE AS\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(dum)([ ,;!?.])', r'\\1de um\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(duma)([ ,;!?.])', r'\\1de uma\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(duns)([ ,;!?.])', r'\\1de uns\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(dumas)([ ,;!?.])', r'\\1de umas\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(Dum)([ ,;!?.])', r'De um\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Duma)([ ,;!?.])', r'De uma\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Duns)([ ,;!?.])', r'De uns\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Dumas)([ ,;!?.])', r'De umas\\2', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'(DUM)([ ,;!?.])', r'DE UM\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DUMA)([ ,;!?.])', r'DE UMA\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DUNS)([ ,;!?.])', r'DE UNS\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DUMAS)([ ,;!?.])', r'DE UMAS\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(dele)([ ,;!?.])', r'\\1de ele\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(dela)([ ,;!?.])', r'\\1de ela\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(deles)([ ,;!?.])', r'\\1de eles\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(delas)([ ,;!?.])', r'\\1de elas\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(Dele)([ ,;!?.])', r'De ele\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Dela)([ ,;!?.])', r'De ela\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Deles)([ ,;!?.])', r'De eles\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Delas)([ ,;!?.])', r'De elas\\2', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'(DELE)([ ,;!?.])', r'DE ELE\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DELA)([ ,;!?.])', r'DE ELA\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DELES)([ ,;!?.])', r'DE ELES\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DELAS)([ ,;!?.])', r'DE ELAS\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(deste)([ ,;!?.])', r'\\1de este\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(desta)([ ,;!?.])', r'\\1de esta\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(destes)([ ,;!?.])', r'\\1de estes\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(destas)([ ,;!?.])', r'\\1de estas\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(disto)([ ,;!?.])', r'\\1de isto\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(desse)([ ,;!?.])', r'\\1de esse\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(dessa)([ ,;!?.])', r'\\1de essa\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(desses)([ ,;!?.])', r'\\1de esses\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(dessas)([ ,;!?.])', r'\\1de essas\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(disso)([ ,;!?.])', r'\\1de isso\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(daquele)([ ,;!?.])', r'\\1de aquele\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(daquela)([ ,;!?.])', r'\\1de aquela\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(daqueles)([ ,;!?.])', r'\\1de aqueles\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(daquelas)([ ,;!?.])', r'\\1de aquelas\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(daquilo)([ ,;!?.])', r'\\1de aquilo\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(doutro)([ ,;!?.])', r'\\1de outro\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(doutra)([ ,;!?.])', r'\\1de outra\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(doutros)([ ,;!?.])', r'\\1de outros\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(doutras)([ ,;!?.])', r'\\1de outras\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(daqui)([ ,;!?.])', r'\\1de aqui\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(daí)([ ,;!?.])', r'\\1de aí\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(dali)([ ,;!?.])', r'\\1de ali\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(dalém)([ ,;!?.])', r'\\1de além\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(Deste)([ ,;!?.])', r'De este\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Desta)([ ,;!?.])', r'De esta\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Destes)([ ,;!?.])', r'De estes\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Destas)([ ,;!?.])', r'De estas\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Disto)([ ,;!?.])', r'De isto\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Desse)([ ,;!?.])', r'De esse\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Dessa)([ ,;!?.])', r'De essa\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Desses)([ ,;!?.])', r'De esses\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Dessas)([ ,;!?.])', r'De essas\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Disso)([ ,;!?.])', r'De isso\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Daquele)([ ,;!?.])', r'De aquele\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Daquela)([ ,;!?.])', r'De aquela\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Daqueles)([ ,;!?.])', r'De aqueles\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Daquelas)([ ,;!?.])', r'De aquelas\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Daquilo)([ ,;!?.])', r'De aquilo\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Doutro)([ ,;!?.])', r'De outro\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Doutra)([ ,;!?.])', r'De outra\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Doutros)([ ,;!?.])', r'De outros\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Doutras)([ ,;!?.])', r'De outras\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Daqui)([ ,;!?.])', r'De aqui\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Daí)([ ,;!?.])', r'De aí\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Dali)([ ,;!?.])', r'De ali\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Dalém)([ ,;!?.])', r'De além\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(DESTE)([ ,;!?.])', r'DE ESTE\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DESTA)([ ,;!?.])', r'DE ESTA\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DESTES)([ ,;!?.])', r'DE ESTES\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DESTAS)([ ,;!?.])', r'DE ESTAS\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DISTO)([ ,;!?.])', r'DE ISTO\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DESSE)([ ,;!?.])', r'DE ESSE\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DESSA)([ ,;!?.])', r'DE ESSA\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DESSES)([ ,;!?.])', r'DE ESSES\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DESSAS)([ ,;!?.])', r'DE ESSAS\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DISSO)([ ,;!?.])', r'DE ISSO\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DAQUELE)([ ,;!?.])', r'DE AQUELE\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DAQUELA)([ ,;!?.])', r'DE AQUELA\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DAQUELES)([ ,;!?.])', r'DE AQUELES\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DAQUELAS)([ ,;!?.])', r'DE AQUELAS\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DAQUILO)([ ,;!?.])', r'DE AQUILO\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DOUTRO)([ ,;!?.])', r'DE OUTRO\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DOUTRA)([ ,;!?.])', r'DE OUTRA\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DOUTROS)([ ,;!?.])', r'DE OUTROS\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DOUTRAS)([ ,;!?.])', r'DE OUTRAS\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DAQUI)([ ,;!?.])', r'DE AQUI\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DAÍ)([ ,;!?.])', r'DE AÍ\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DALI)([ ,;!?.])', r'DE ALI\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(DALÉM)([ ,;!?.])', r'DE ALÉM\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(no)([ ,;!?.])', r'\\1em o\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(na)([ ,;!?.])', r'\\1em a\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nos)([ ,;!?.])', r'\\1em os\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nas)([ ,;!?.])', r'\\1em as\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(No)([ ,;!?.])', r'\\1Em o\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(Na)([ ,;!?.])', r'\\1Em a\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(Nos)([ ,;!?.])', r'\\1Em os\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(Nas)([ ,;!?.])', r'\\1Em as\\3', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'( )(NO)([ ,;!?.])', r'\\1EM O\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(NA)([ ,;!?.])', r'\\1EM A\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(NOS)([ ,;!?.])', r'\\1EM OS\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(NAS)([ ,;!?.])', r'\\1EM AS\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(num)([ ,;!?.])', r'\\1em um\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(numa)([ ,;!?.])', r'\\1em uma\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nuns)([ ,;!?.])', r'\\1em uns\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(numas)([ ,;!?.])', r'\\1em umas\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(Num)([ ,;!?.])', r'Em um\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Numa)([ ,;!?.])', r'Em uma\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Nuns)([ ,;!?.])', r'Em uns\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Numas)([ ,;!?.])', r'Em umas\\2', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'(NUM)([ ,;!?.])', r'EM UM\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NUMA)([ ,;!?.])', r'EM UMA\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NUNS)([ ,;!?.])', r'EM UNS\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NUMAS)([ ,;!?.])', r'EM UMAS\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(nele)([ ,;!?.])', r'\\1em ele\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nela)([ ,;!?.])', r'\\1em ela\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(neles)([ ,;!?.])', r'\\1em eles\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nelas)([ ,;!?.])', r'\\1em elas\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(Nele)([ ,;!?.])', r'Em ele\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Nela)([ ,;!?.])', r'Em ela\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Neles)([ ,;!?.])', r'Em eles\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Nelas)([ ,;!?.])', r'Em elas\\2', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'(NELE)([ ,;!?.])', r'EM ELE\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NELA)([ ,;!?.])', r'EM ELA\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NELES)([ ,;!?.])', r'EM ELES\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NELAS)([ ,;!?.])', r'EM ELAS\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(neste)([ ,;!?.])', r'\\1em este\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nesta)([ ,;!?.])', r'\\1em esta\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nestes)([ ,;!?.])', r'\\1em estes\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nestas)([ ,;!?.])', r'\\1em estas\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nisto)([ ,;!?.])', r'\\1em isto\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nesse)([ ,;!?.])', r'\\1em esse\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nessa)([ ,;!?.])', r'\\1em essa\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nesses)([ ,;!?.])', r'\\1em esses\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nessas)([ ,;!?.])', r'\\1em essas\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(nisso)([ ,;!?.])', r'\\1em isso\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(naquele)([ ,;!?.])', r'\\1em aquele\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(naquela)([ ,;!?.])', r'\\1em aquela\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(naqueles)([ ,;!?.])', r'\\1em aqueles\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(naquelas)([ ,;!?.])', r'\\1em aquelas\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(naquilo)([ ,;!?.])', r'\\1em aquilo\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(Neste)([ ,;!?.])', r'Em este\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Nesta)([ ,;!?.])', r'Em esta\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Nestes)([ ,;!?.])', r'Em estes\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Nestas)([ ,;!?.])', r'Em estas\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Nisto)([ ,;!?.])', r'Em isto\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Nesse)([ ,;!?.])', r'Em esse\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Nessa)([ ,;!?.])', r'Em essa\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Nesses)([ ,;!?.])', r'Em esses\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Nessas)([ ,;!?.])', r'Em essas\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Nisso)([ ,;!?.])', r'Em isso\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Naquele)([ ,;!?.])', r'Em aquele\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Naquela)([ ,;!?.])', r'Em aquela\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Naqueles)([ ,;!?.])', r'Em aqueles\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Naquelas)([ ,;!?.])', r'Em aquelas\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Naquilo)([ ,;!?.])', r'Em aquilo\\2', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'(NESTE)([ ,;!?.])', r'EM ESTE\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NESTA)([ ,;!?.])', r'EM ESTA\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NESTES)([ ,;!?.])', r'EM ESTES\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NESTAS)([ ,;!?.])', r'EM ESTAS\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NISTO)([ ,;!?.])', r'EM ISTO\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NESSE)([ ,;!?.])', r'EM ESSE\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NESSA)([ ,;!?.])', r'EM ESSA\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NESSES)([ ,;!?.])', r'EM ESSES\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NESSAS)([ ,;!?.])', r'EM ESSAS\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NISSO)([ ,;!?.])', r'EM ISSO\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NAQUELE)([ ,;!?.])', r'EM AQUELE\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NAQUELA)([ ,;!?.])', r'EM AQUELA\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NAQUELES)([ ,;!?.])', r'EM AQUELES\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NAQUELAS)([ ,;!?.])', r'EM AQUELAS\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(NAQUILO)([ ,;!?.])', r'EM AQUILO\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(pelo)([ ,;!?.])', r'\\1por o\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(pela)([ ,;!?.])', r'\\1por a\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(pelos)([ ,;!?.])', r'\\1por os\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(pelas)([ ,;!?.])', r'\\1por as\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(Pelo)([ ,;!?.])', r'Por o\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Pela)([ ,;!?.])', r'Por a\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Pelos)([ ,;!?.])', r'Por os\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Pelas)([ ,;!?.])', r'Por as\\2', text, flags=re.U)\n",
        "    \n",
        "    text = re.sub(r'(PELO)([ ,;!?.])', r'POR O\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(PELA)([ ,;!?.])', r'POR A\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(PELOS)([ ,;!?.])', r'POR OS\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(PELAS)([ ,;!?.])', r'POR AS\\2', text, flags=re.U)\n",
        " \n",
        "    return text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYOqQdjLB_i0"
      },
      "source": [
        "def realize(text):\n",
        "    text = re.sub(r'( )(com um)([ ,;!?.])', r'\\1 cum\\3', text, flags=re.U)\n",
        "    text = re.sub(r'(Com um)([ ,;!?.])', r'Cum\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(de o)([ ,;!?.])', r'\\1do\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de a)([ ,;!?.])', r'\\1da\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de os)([ ,;!?.])', r'\\1dos\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de as)([ ,;!?.])', r'\\1das\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(De o)([ ,;!?.])', r'Do\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De a)([ ,;!?.])', r'Da\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De os)([ ,;!?.])', r'Dos\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De as)([ ,;!?.])', r'Das\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(de um)([ ,;!?.])', r'\\1dum\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de uma)([ ,;!?.])', r'\\1duma\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de uns)([ ,;!?.])', r'\\1duns\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de umas)([ ,;!?.])', r'\\1dumas\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(De um)([ ,;!?.])', r'Dum\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De uma)([ ,;!?.])', r'Duma\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De uns)([ ,;!?.])', r'Duns\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De umas)([ ,;!?.])', r'Dumas\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(de ele)([ ,;!?.])', r'\\1dele\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de ela)([ ,;!?.])', r'\\1dela\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de eles)([ ,;!?.])', r'\\1deles\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de elas)([ ,;!?.])', r'\\1delas\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(De ele)([ ,;!?.])', r'Dele\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De ela)([ ,;!?.])', r'Dela\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De eles)([ ,;!?.])', r'Deles\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De elas)([ ,;!?.])', r'Delas\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(de este)([ ,;!?.])', r'\\1deste\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de esta)([ ,;!?.])', r'\\1desta\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de estes)([ ,;!?.])', r'\\1destes\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de estas)([ ,;!?.])', r'\\1destas\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de isto)([ ,;!?.])', r'\\1disto\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de esse)([ ,;!?.])', r'\\1desse\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de essa)([ ,;!?.])', r'\\1dessa\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de esses)([ ,;!?.])', r'\\1desses\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de essas)([ ,;!?.])', r'\\1dessas\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de isso)([ ,;!?.])', r'\\1disso\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de aquele)([ ,;!?.])', r'\\1daquele\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de aquela)([ ,;!?.])', r'\\1daquela\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de aqueles)([ ,;!?.])', r'\\1daqueles\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de aquelas)([ ,;!?.])', r'\\1daquelas\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de aquilo)([ ,;!?.])', r'\\1daquilo\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de outro)([ ,;!?.])', r'\\1doutro\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de outra)([ ,;!?.])', r'\\1doutra\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de outros)([ ,;!?.])', r'\\1doutros\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de outras)([ ,;!?.])', r'\\1doutras\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de aqui)([ ,;!?.])', r'\\1daqui\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de aí)([ ,;!?.])', r'\\1daí\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de ali)([ ,;!?.])', r'\\1dali\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(de além)([ ,;!?.])', r'\\1dalém\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(De este)([ ,;!?.])', r'Deste\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De esta)([ ,;!?.])', r'Desta\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De estes)([ ,;!?.])', r'Destes\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De estas)([ ,;!?.])', r'Destas\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De isto)([ ,;!?.])', r'Disto\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De esse)([ ,;!?.])', r'Desse\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De essa)([ ,;!?.])', r'Dessa\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De esses)([ ,;!?.])', r'Desses\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De essas)([ ,;!?.])', r'Dessas\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De isso)([ ,;!?.])', r'Disso\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De aquele)([ ,;!?.])', r'Daquele\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De aquela)([ ,;!?.])', r'Daquela\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De aqueles)([ ,;!?.])', r'Daqueles\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De aquelas)([ ,;!?.])', r'Daquelas\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De aquilo)([ ,;!?.])', r'Daquilo\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De outro)([ ,;!?.])', r'Doutro\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De outra)([ ,;!?.])', r'Doutra\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De outros)([ ,;!?.])', r'Doutros\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De outras)([ ,;!?.])', r'Doutras\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De aqui)([ ,;!?.])', r'Daqui\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De aí)([ ,;!?.])', r'Daí\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De ali)([ ,;!?.])', r'Dali\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(De além)([ ,;!?.])', r'Dalém\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(em o)([ ,;!?.])', r'\\1no\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em a)([ ,;!?.])', r'\\1na\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em os)([ ,;!?.])', r'\\1nos\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em as)([ ,;!?.])', r'\\1nas\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(Em o)([ ,;!?.])', r'No\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em a)([ ,;!?.])', r'Na\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em os)([ ,;!?.])', r'Nos\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em as)([ ,;!?.])', r'Nas\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(em um)([ ,;!?.])', r'\\1num\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em uma)([ ,;!?.])', r'\\1numa\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em uns)([ ,;!?.])', r'\\1nuns\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em umas)([ ,;!?.])', r'\\1numas\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(Em um)([ ,;!?.])', r'Num\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em uma)([ ,;!?.])', r'Numa\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em uns)([ ,;!?.])', r'Nuns\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em umas)([ ,;!?.])', r'Numas\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(em ele)([ ,;!?.])', r'\\1nele\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em ela)([ ,;!?.])', r'\\1nela\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em eles)([ ,;!?.])', r'\\1neles\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em elas)([ ,;!?.])', r'\\1nelas\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(Em ele)([ ,;!?.])', r'Nele\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em ela)([ ,;!?.])', r'Nela\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em eles)([ ,;!?.])', r'Neles\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em elas)([ ,;!?.])', r'Nelas\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(em este)([ ,;!?.])', r'\\1neste\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em esta)([ ,;!?.])', r'\\1nesta\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em estes)([ ,;!?.])', r'\\1nestes\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em estas)([ ,;!?.])', r'\\1nestas\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em isto)([ ,;!?.])', r'\\1nisto\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em esse)([ ,;!?.])', r'\\1nesse\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em essa)([ ,;!?.])', r'\\1nessa\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em esses)([ ,;!?.])', r'\\1nesses\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em essas)([ ,;!?.])', r'\\1nessas\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em isso)([ ,;!?.])', r'\\1nisso\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em aquele)([ ,;!?.])', r'\\1naquele\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em aquela)([ ,;!?.])', r'\\1naquela\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em aqueles)([ ,;!?.])', r'\\1naqueles\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em aquelas)([ ,;!?.])', r'\\1naquelas\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(em aquilo)([ ,;!?.])', r'\\1naquilo\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(Em este)([ ,;!?.])', r'Neste\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em esta)([ ,;!?.])', r'Nesta\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em estes)([ ,;!?.])', r'Nestes\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em estas)([ ,;!?.])', r'Nestas\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em isto)([ ,;!?.])', r'Nisto\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em esse)([ ,;!?.])', r'Nesse\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em essa)([ ,;!?.])', r'Nessa\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em esses)([ ,;!?.])', r'Nesses\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em essas)([ ,;!?.])', r'Nessas\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em isso)([ ,;!?.])', r'Nisso\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em aquele)([ ,;!?.])', r'Naquele\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em aquela)([ ,;!?.])', r'Naquela\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em aqueles)([ ,;!?.])', r'Naqueles\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em aquelas)([ ,;!?.])', r'Naquelas\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Em aquilo)([ ,;!?.])', r'Naquilo\\2', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'( )(por o)([ ,;!?.])', r'\\1pelo\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(por a)([ ,;!?.])', r'\\1pela\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(por os)([ ,;!?.])', r'\\1pelos\\3', text, flags=re.U)\n",
        "    text = re.sub(r'( )(por as)([ ,;!?.])', r'\\1pelas\\3', text, flags=re.U)\n",
        " \n",
        "    text = re.sub(r'(Por o)([ ,;!?.])', r'Pelo\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Por a)([ ,;!?.])', r'Pela\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Por os)([ ,;!?.])', r'Pelos\\2', text, flags=re.U)\n",
        "    text = re.sub(r'(Por as)([ ,;!?.])', r'Pelas\\2', text, flags=re.U)\n",
        " \n",
        "    text = text.replace(u' a a ', u' à ')\n",
        "    text = text.replace(u'A a ', u'À ')\n",
        "    text = text.replace(u' a as ', u' às ')\n",
        "    text = text.replace(u'A as ', u'Às ')\n",
        " \n",
        "    text = re.sub(r'( )(a o)([ ,;!?.])', r'\\1ao\\3', text, flags=re.U)\n",
        "    text = re.sub(r'(A o)([ ,;!?.])', r'Ao\\2', text, flags=re.U)\n",
        "    text = re.sub(r'( )(a os)([ ,;!?.])', r'\\1aos\\3', text, flags=re.U)\n",
        "    text = re.sub(r'(A os)([ ,;!?.])', r'Aos\\2', text, flags=re.U)\n",
        " \n",
        "    return text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi5KorkNGGhm"
      },
      "source": [
        "<p> You can use the above functions as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnA8NdHxB_ki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c66dd0-21bf-4b83-bc85-d0e6f991e3a4"
      },
      "source": [
        "sentence = \"Esta é uma sentença que será modificada pela função parse().\"\n",
        "parsed_sentence = parse(sentence)\n",
        "print(sentence)\n",
        "print(parsed_sentence)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Esta é uma sentença que será modificada pela função parse().\n",
            "Esta é uma sentença que será modificada por a função parse().\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1F041pHB_mO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37644ae4-7157-4912-c87c-c921c3dec7b2"
      },
      "source": [
        "sentence = \"Esta é uma sentença que será modificada por a função realize().\"\n",
        "realized_sentence = realize(sentence)\n",
        "print(sentence)\n",
        "print(realized_sentence)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Esta é uma sentença que será modificada por a função realize().\n",
            "Esta é uma sentença que será modificada pela função realize().\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQlBxia5f2MO"
      },
      "source": [
        "---\n",
        "<h1> Functions for text normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEoznSe9hJZ2"
      },
      "source": [
        "Lowering sentences is simple, just use the lower() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc2U5J7Tf9Qk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495c4e78-1974-499e-afa6-49956d3e089c"
      },
      "source": [
        "sentence = \"ESTA é uma SENTENÇA que será modificada pela FUNÇÃO lower().\"\n",
        "lower_sentence = sentence.lower()\n",
        "print(sentence)\n",
        "print(lower_sentence)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ESTA é uma SENTENÇA que será modificada pela FUNÇÃO lower().\n",
            "esta é uma sentença que será modificada pela função lower().\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr_5ruDuihWW"
      },
      "source": [
        "It is also possible to do the reverse, using the upper() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsOw0Pruinth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a7f32ec-2cfb-4539-abaf-fc6bf79315da"
      },
      "source": [
        "sentence = \"ESTA é uma SENTENÇA que será modificada pela FUNÇÃO upper().\"\n",
        "upper_sentence = sentence.upper()\n",
        "print(sentence)\n",
        "print(upper_sentence)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ESTA é uma SENTENÇA que será modificada pela FUNÇÃO upper().\n",
            "ESTA É UMA SENTENÇA QUE SERÁ MODIFICADA PELA FUNÇÃO UPPER().\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uESzdVKhUnt"
      },
      "source": [
        "Removing accents from sentences is simple, just use the lower() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UIRBKtUf9a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef664b4c-9575-460c-9264-9b1d55b19b52"
      },
      "source": [
        "sentence = \"Esta é uma sentença que será modificada pela função unidecode.unidecode().\"\n",
        "no_accents_sentence = unidecode.unidecode(sentence)\n",
        "print(sentence)\n",
        "print(no_accents_sentence)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Esta é uma sentença que será modificada pela função unidecode.unidecode().\n",
            "Esta e uma sentenca que sera modificada pela funcao unidecode.unidecode().\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQVjurRohiut"
      },
      "source": [
        "You can mix varios functions to fit your need, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGfd4aNnhpDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84961490-875e-4462-8902-e54331730c2e"
      },
      "source": [
        "sentence = \"ESTA é uma sentença que será MODIFICADA pela função lower(), unidecode.unidecode() e parse()\"\n",
        "no_accents_sentence = unidecode.unidecode(sentence)\n",
        "lower_sentence = no_accents_sentence.lower()\n",
        "final_sentence = parse(lower_sentence)\n",
        "print(sentence)\n",
        "print(final_sentence)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ESTA é uma sentença que será MODIFICADA pela função lower(), unidecode.unidecode() e parse()\n",
            "esta e uma sentenca que sera modificada por a funcao lower(), unidecode.unidecode() e parse()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HvquFd6iLSe"
      },
      "source": [
        "It can be done in one line:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDQv_p9TiONG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8486672-f017-4cb1-b2ba-2744fb08eb52"
      },
      "source": [
        "sentence = \"ESTA é uma sentença que será MODIFICADA pela função lower(), unidecode.unidecode() e parse()\"\n",
        "final_sentence = unidecode.unidecode(parse(sentence.lower()))\n",
        "print(sentence)\n",
        "print(final_sentence)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ESTA é uma sentença que será MODIFICADA pela função lower(), unidecode.unidecode() e parse()\n",
            "esta e uma sentenca que sera modificada por a funcao lower(), unidecode.unidecode() e parse()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aGz9dRAQ_x6"
      },
      "source": [
        "---\n",
        "<h1> Regex\n",
        "\n",
        "<h2> Use of regular expressions to tokenize text.\n",
        "\n",
        "Using Regex, you can create various rules to best fit your context. There is no \"formula\" ready to tokenize a text with Regex. Often, the best way out is to go testing and see what solves your problem.\n",
        "It's possible to test a number of regex rules at: [Regex](https://regexr.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFL8cFl1T_VT"
      },
      "source": [
        "The text used in the next example was taken from \"Grande Sertão - Veredas\" by Guimarães Rosa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o53QaDMVWCh"
      },
      "source": [
        "As follows:\n",
        "\n",
        "Do demo? Não gloso. Senhor pergunte aos moradores. Em falso receio, desfalam no nome dele – dizem só: o Que-Diga. Vote! não... Quem muito se evita, se convive. Sentença num Aristides – o que existe no buritizal primeiro desta minha mão direita, chamado a Vereda-da-Vaca-Mansa-deSanta-Rita – todo o mundo crê: ele não pode passar em três lugares, designados: porque então a gente escuta um chorinho, atrás, e uma vozinha que avisando: – “Eu já vou! Eu já vou!...” – que é o capiroto, o que-diga... E um José Simpilício – quem qualquer daqui jura ele tem um capeta em casa, miúdo satanazim, preso obrigado a ajudar em toda ganância que executa; razão que o Simpilício se empresa em vias de completar de rico. Apre, por isso dizem também que a besta pra ele rupeia, nega de banda, não deixando, quando ele quer amontar... Superstição. José Simpilício e Aristides, mesmo estão se engordando, de assim não -ouvir ou ouvir. Ainda o senhor estude: agora mesmo, nestes dias de época, tem gente porfalando que o Diabo próprio parou, de passagem, no Andrequicé. Um Moço de fora, teria aparecido, e lá se louvou que, para aqui vir – normal, a cavalo, dum dia-e-meio – ele era capaz que só com uns vinte min utos bastava... porque costeava o Rio do Chico pelas cabeceiras! Ou, também, quem sabe – sem ofensas – não terá sido, por um exemplo, até mesmo o senhor quem se anunciou assim, quando passou por lá, por prazido divertimento engraçado? Há-de, não me dê crime, sei que não foi. E mal eu não quis. Só que uma pergunta, em hora, às vezes, clareia razão de paz. Mas, o senhor entenda: o tal moço, se há, quis mangar. Pois, hem, que, despontar o Rio pelas nascentes, será a mesma coisa que um se redobrar nos intern os deste nosso Estado nosso, custante viagem de uns três meses... Então? Que- Diga? Doideira. A fantasiação. E, o respeito de dar a ele assim esses nomes de rebuço, é que é mesmo um querer invocar que ele forme forma, com as presenças!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dNy7ulgHhbo"
      },
      "source": [
        "text = \"Do demo? Não gloso. Senhor pergunte aos moradores. Em falso receio, desfalam no nome dele – dizem só: o Que-Diga. Vote! não... Quem muito se evita, se convive. Sentença num Aristides – o que existe no buritizal primeiro desta minha mão direita, chamado a Vereda-da-Vaca-Mansa-deSanta-Rita – todo o mundo crê: ele não pode passar em três lugares, designados: porque então a gente escuta um chorinho, atrás, e uma vozinha que avisando: – “Eu já vou! Eu já vou!...” – que é o capiroto, o que-diga... E um José Simpilício – quem qualquer daqui jura ele tem um capeta em casa, miúdo satanazim, preso obrigado a ajudar em toda ganância que executa; razão que o Simpilício se empresa em vias de completar de rico. Apre, por isso dizem também que a besta pra ele rupeia, nega de banda, não deixando, quando ele quer amontar... Superstição. José Simpilício e Aristides, mesmo estão se engordando, de assim não -ouvir ou ouvir. Ainda o senhor estude: agora mesmo, nestes dias de época, tem gente porfalando que o Diabo próprio parou, de passagem, no Andrequicé. Um Moço de fora, teria aparecido, e lá se louvou que, para aqui vir – normal, a cavalo, dum dia-e-meio – ele era capaz que só com uns vinte min utos bastava... porque costeava o Rio do Chico pelas cabeceiras! Ou, também, quem sabe – sem ofensas – não terá sido, por um exemplo, até mesmo o senhor quem se anunciou assim, quando passou por lá, por prazido divertimento engraçado? Há-de, não me dê crime, sei que não foi. E mal eu não quis. Só que uma pergunta, em hora, às vezes, clareia razão de paz. Mas, o senhor entenda: o tal moço, se há, quis mangar. Pois, hem, que, despontar o Rio pelas nascentes, será a mesma coisa que um se redobrar nos intern os deste nosso Estado nosso, custante viagem de uns três meses... Então? Que- Diga? Doideira. A fantasiação. E, o respeito de dar a ele assim esses nomes de rebuço, é que é mesmo um querer invocar que ele forme forma, com as presenças!\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLp9JzAhHheC",
        "outputId": "af15a07b-f1e4-4f31-a521-8c624edd9c4a"
      },
      "source": [
        "sentence_list = re.split(r'(?<=[^A-Z].[.?!;]) +(?=[A-Z]|[a-z]|[0-9])', text)\n",
        "for sentence in sentence_list:\n",
        "    print(sentence)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Do demo?\n",
            "Não gloso.\n",
            "Senhor pergunte aos moradores.\n",
            "Em falso receio, desfalam no nome dele – dizem só: o Que-Diga.\n",
            "Vote!\n",
            "não...\n",
            "Quem muito se evita, se convive.\n",
            "Sentença num Aristides – o que existe no buritizal primeiro desta minha mão direita, chamado a Vereda-da-Vaca-Mansa-deSanta-Rita – todo o mundo crê: ele não pode passar em três lugares, designados: porque então a gente escuta um chorinho, atrás, e uma vozinha que avisando: – “Eu já vou!\n",
            "Eu já vou!...” – que é o capiroto, o que-diga...\n",
            "E um José Simpilício – quem qualquer daqui jura ele tem um capeta em casa, miúdo satanazim, preso obrigado a ajudar em toda ganância que executa;\n",
            "razão que o Simpilício se empresa em vias de completar de rico.\n",
            "Apre, por isso dizem também que a besta pra ele rupeia, nega de banda, não deixando, quando ele quer amontar...\n",
            "Superstição.\n",
            "José Simpilício e Aristides, mesmo estão se engordando, de assim não -ouvir ou ouvir.\n",
            "Ainda o senhor estude: agora mesmo, nestes dias de época, tem gente porfalando que o Diabo próprio parou, de passagem, no Andrequicé.\n",
            "Um Moço de fora, teria aparecido, e lá se louvou que, para aqui vir – normal, a cavalo, dum dia-e-meio – ele era capaz que só com uns vinte min utos bastava...\n",
            "porque costeava o Rio do Chico pelas cabeceiras!\n",
            "Ou, também, quem sabe – sem ofensas – não terá sido, por um exemplo, até mesmo o senhor quem se anunciou assim, quando passou por lá, por prazido divertimento engraçado?\n",
            "Há-de, não me dê crime, sei que não foi.\n",
            "E mal eu não quis.\n",
            "Só que uma pergunta, em hora, às vezes, clareia razão de paz.\n",
            "Mas, o senhor entenda: o tal moço, se há, quis mangar.\n",
            "Pois, hem, que, despontar o Rio pelas nascentes, será a mesma coisa que um se redobrar nos intern os deste nosso Estado nosso, custante viagem de uns três meses...\n",
            "Então?\n",
            "Que- Diga?\n",
            "Doideira.\n",
            "A fantasiação.\n",
            "E, o respeito de dar a ele assim esses nomes de rebuço, é que é mesmo um querer invocar que ele forme forma, com as presenças!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waPvv6R7UV76"
      },
      "source": [
        "What this regular expression does is match all the spaces in the text which have at least three characters before it, being the first different from A-Z, the second any character, and the third being amongst \" . ? ! ; \", and a letter or number after it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZFjKzGekTv3"
      },
      "source": [
        "---\n",
        "<h1> NLP model application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWl8KQudkYFU"
      },
      "source": [
        "The following cells apply the Portuguese NLP Model from Stanza in a sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTotJfWNHhgA",
        "outputId": "8a07a7f9-960a-4ec5-8046-aee73be8d2f9"
      },
      "source": [
        "# Load the model\n",
        "nlp = stanza.Pipeline('pt', use_gpu=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-16 12:42:33 INFO: Loading these models for language: pt (Portuguese):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | bosque  |\n",
            "| mwt       | bosque  |\n",
            "| pos       | bosque  |\n",
            "| lemma     | bosque  |\n",
            "| depparse  | bosque  |\n",
            "=======================\n",
            "\n",
            "2021-08-16 12:42:33 INFO: Use device: cpu\n",
            "2021-08-16 12:42:33 INFO: Loading: tokenize\n",
            "2021-08-16 12:42:33 INFO: Loading: mwt\n",
            "2021-08-16 12:42:33 INFO: Loading: pos\n",
            "2021-08-16 12:42:33 INFO: Loading: lemma\n",
            "2021-08-16 12:42:34 INFO: Loading: depparse\n",
            "2021-08-16 12:42:34 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL0LAYBKHhil",
        "outputId": "9a822bfc-b6e5-42f1-cb0e-5d44971c23c1"
      },
      "source": [
        "sentence = \"O modelo de NLP será aplicado nesta sentença.\"\n",
        "# Apply the model in the sentence\n",
        "doc = nlp(sentence)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM64Vml2Hhkj",
        "outputId": "a0c6336c-bd3c-42c1-d7d8-79181041f195"
      },
      "source": [
        "# shows every words in the sentence\n",
        "for sent in doc.sentences:\n",
        "  for word in sent.words:\n",
        "    print(word.text)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\n",
            "modelo\n",
            "de\n",
            "NLP\n",
            "será\n",
            "aplicado\n",
            "em\n",
            "esta\n",
            "sentença\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNcELbcAmR8o"
      },
      "source": [
        "It is worth noting that some NLP models have the parse() function built in. In some cases, the model can miss the parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVTNaWrPHhmp",
        "outputId": "d3add617-bdb8-45bf-d621-0139a03b6522"
      },
      "source": [
        "# shows every upos tag in the sentence\n",
        "for sent in doc.sentences:\n",
        "  for word in sent.words:\n",
        "    print(word.upos)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DET\n",
            "NOUN\n",
            "ADP\n",
            "PROPN\n",
            "AUX\n",
            "VERB\n",
            "ADP\n",
            "DET\n",
            "NOUN\n",
            "PUNCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mOO15M1Hho3",
        "outputId": "f6170b7e-7aae-4f71-d83e-d73f23362aba"
      },
      "source": [
        "# shows every dependency tag and its head in the sentence\n",
        "for sent in doc.sentences:\n",
        "  for word in sent.words:\n",
        "    print(word.deprel + \" - \" +  str(word.head))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "det - 2\n",
            "nsubj:pass - 6\n",
            "case - 4\n",
            "nmod - 2\n",
            "aux:pass - 6\n",
            "root - 0\n",
            "case - 9\n",
            "det - 9\n",
            "obl - 6\n",
            "punct - 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkGr2sCunRHA"
      },
      "source": [
        "You can get and test out every information about the tokens in the sentence with:\n",
        "* word.id - returns the ID of the token\n",
        "* word.text - returns the token\n",
        "* word.lemma - returns the Lemma of the token\n",
        "* word.upos - returns the Universal POS-tag of the token\n",
        "* word.feats - returns the morphological features of the token\n",
        "* word.head - returns the head token of the dependency relation\n",
        "* word.deprel - returns the dependency relation of the token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B1WZW2joRLG"
      },
      "source": [
        "Note: Not every NLP model or library has the same syntax to get the tokens informations or work with the model. You can always look at the library documentation to find out how everything works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgJi1GcYpOjP"
      },
      "source": [
        "---\n",
        "<h1> Putting it all together\n",
        "\n",
        "Now, lets apply the NLP model in some normalized sentences, taken from a .txt file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frD5Fi7CHhrD",
        "outputId": "1a316717-dace-4ecf-8c53-a40e7a268d65"
      },
      "source": [
        "# show work PATH\n",
        "print(PATH)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data/corpus/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbCLJ51tqUOU"
      },
      "source": [
        "If you're using google colab, you can upload your corpus under the \"corpus/\" folder. If you're running locally, you can put your corpus inside the folder of your PATH."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aOaUUFqrgXO",
        "outputId": "9bb78716-3822-4f3e-a16a-381e3b2f8d76"
      },
      "source": [
        "# Load the model\n",
        "nlp = stanza.Pipeline('pt', use_gpu=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-16 12:42:34 INFO: Loading these models for language: pt (Portuguese):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | bosque  |\n",
            "| mwt       | bosque  |\n",
            "| pos       | bosque  |\n",
            "| lemma     | bosque  |\n",
            "| depparse  | bosque  |\n",
            "=======================\n",
            "\n",
            "2021-08-16 12:42:34 INFO: Use device: cpu\n",
            "2021-08-16 12:42:34 INFO: Loading: tokenize\n",
            "2021-08-16 12:42:34 INFO: Loading: mwt\n",
            "2021-08-16 12:42:34 INFO: Loading: pos\n",
            "2021-08-16 12:42:35 INFO: Loading: lemma\n",
            "2021-08-16 12:42:35 INFO: Loading: depparse\n",
            "2021-08-16 12:42:36 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75XAVO6FrgaT"
      },
      "source": [
        "# Open the Writing File (where the informations will be stored) - Create the Writing File if it does not exist.\n",
        "fw = open(PATH + 'result_corpus.conllu', 'w', encoding='utf-8')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZoj86ivoKyY"
      },
      "source": [
        "# Open your corpus containing the sentences\n",
        "# This corpus must be split into sentences (each line has a sentence)\n",
        "with open(PATH + 'your_corpus.txt', 'r', encoding='utf-8') as f:\n",
        "  text = f.read()\n",
        "  idsentence = 1\n",
        "  \n",
        "  # Iterate through sentences\n",
        "  for sentence in text.split(\"\\n\"):\n",
        "    # Write the header of the sentence in the CoNLL-U format\n",
        "    fw.write('# text = ' + sentence)\n",
        "    fw.write(\"\\n# source = \" + \"Grande Sertão - Veredas by Guimarães Rosa\")\n",
        "    fw.write('\\n# sent_id = GR-%d' %idsentence)\n",
        "    fw.write('\\n# id = %d' %idsentence)\n",
        "    idsentence = idsentence + 1\n",
        "    idword = 1\n",
        "\n",
        "    # Apply the model in the sentence    \n",
        "    doc = nlp(sentence)\n",
        "    \n",
        "    # Iterate through the tokens\n",
        "    for sent in doc.sentences:\n",
        "      for word in sent.words:\n",
        "        # Write the information about the token in the CoNLL-U format\n",
        "        fw.write('\\n%d' %idword + '\\t' + word.text + '\\t' + word.lemma + '\\t' + word.upos + '\\t_\\t' + str(word.feats) + '\\t' + str(word.head) + '\\t' + word.deprel + '\\t' + \"_\" + '\\t' + \"_\")\n",
        "        idword = idword + 1\n",
        "\n",
        "    fw.write('\\n\\n')\n",
        " \n",
        "# Close the file     \n",
        "fw.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNh841CwvZq7"
      },
      "source": [
        "---\n",
        "<h1> Apply model + Regex + Parsing\n",
        "\n",
        "Often, we don't have an original .txt file ready for use. We can always a few normalizations to fit our need. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHTSlTSJoK1Y"
      },
      "source": [
        "# Open the Writing File (where the informations will be stored) - Create the Writing File if it does not exist.\n",
        "fw = open(PATH + 'result_corpus_text.conllu', 'w', encoding='utf-8')\n",
        "fws = open(PATH + 'sentence_corpus.conllu', 'w', encoding='utf-8')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udF0fV3Fwpsj",
        "outputId": "ff5d772f-d82b-4b6b-efc6-37e43506f1e7"
      },
      "source": [
        "# Open your corpus containing the sentences\n",
        "# This corpus must be split into sentences (each line has a sentence)\n",
        "# This corpus must be organized in a way that you have one paragraph per line\n",
        "print(\"Initialized - Applying Model\")\n",
        "print(\"Initializing timer...\\n\")\n",
        "start_t = time.time()\n",
        "with open(PATH + 'your_corpus_text.txt', 'r', encoding='utf-8') as f:\n",
        "  text = f.read()\n",
        "  idsentence = 1\n",
        "  \n",
        "  # Iterate through sentences\n",
        "  for p in text.split(\"\\n\"):\n",
        "\n",
        "    # Apply Regex rule and split paragraph\n",
        "    sentences = re.split(r'(?<=[^A-Z].[.?!;]) +(?=[A-Z]|[a-z]|[0-9])', p)\n",
        "\n",
        "    # Iterate through split sentences\n",
        "    for sentence in sentences:\n",
        "      # Write the sentences in the new sentence corpus\n",
        "      fws.write(sentence + '\\n')\n",
        "\n",
        "      # Write the header of the sentence in the CoNLL-U format\n",
        "      fw.write('# text = ' + sentence)\n",
        "      fw.write(\"\\n# source = \" + \"Grande Sertão - Veredas by Guimarães Rosa\")\n",
        "      fw.write('\\n# sent_id = GR-%d' %idsentence)\n",
        "      fw.write('\\n# id = %d' %idsentence)\n",
        "      idsentence = idsentence + 1\n",
        "      idword = 1\n",
        "\n",
        "      # Before Appying, lets parse the sentences\n",
        "      sp = parse(sentence)\n",
        "\n",
        "      # Apply the model in the sentence    \n",
        "      doc = nlp(sp)\n",
        "      \n",
        "      # Iterate through the tokens\n",
        "      for sent in doc.sentences:\n",
        "        for word in sent.words:\n",
        "          # Write the information about the token in the CoNLL-U format\n",
        "          fw.write('\\n%d' %idword + '\\t' + word.text + '\\t' + word.lemma + '\\t' + word.upos + '\\t_\\t' + str(word.feats) + '\\t' + str(word.head) + '\\t' + word.deprel + '\\t' + \"_\" + '\\t' + \"_\")\n",
        "          idword = idword + 1\n",
        "\n",
        "      fw.write('\\n\\n')\n",
        "\n",
        "end_t = time.time()\n",
        "final_t = (end_t - start_t)/60\n",
        "print(\"Applied model in %d sentences!\" %idsentence)\n",
        "print(\"Execution time: %.2f minutes\" %final_t)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized - Applying Model\n",
            "Initializing timer...\n",
            "\n",
            "Applied model in 16418 sentences!\n",
            "Execution time: 1821.0518782138824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nFIlTbe67Fp"
      },
      "source": [
        "# Close the file     \n",
        "fw.close()\n",
        "fws.close()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQLYAd7Z3WRG"
      },
      "source": [
        "<h1> Corpus Analysis\n",
        "\n",
        "Here I show how to make a simple analysis throughout the CoNLL-U file. \n",
        "You'll just need to adapt your search in the flagged lines (C)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n6eti5K3sxn"
      },
      "source": [
        "# Write File with the wished analysis. You can change the name of the file in the \"dep_\" and \"nmod_\" camps.\n",
        "fwa = open(PATH + 'dep_' + 'nmod_' + 'analysis.txt', 'w', encoding='utf-8')        #(C)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s4SXGiZ3s0-",
        "outputId": "00203a14-297a-4406-c08f-3e0bde927a05"
      },
      "source": [
        "# Open your annotated corpus in CoNNL-U format.\n",
        "with open(PATH + 'result_corpus_text.conllu', 'r', encoding='utf-8') as f:\n",
        "    \n",
        "    text = f.read()\n",
        "    count = 0\n",
        "       \n",
        "    sentIdlist = []\n",
        "    for wholesentence in text.split(\"\\n\\n\"):\n",
        "        for lines in wholesentence.split(\"\\n\"):\n",
        "            \n",
        "            # Get the ID of the sentence\n",
        "            if '# id = ' in lines:\n",
        "                sentId = lines\n",
        "                sentIdlist.append(sentId)\n",
        "\n",
        "            # Ignore lines that start with # in the CoNNL-U file    \n",
        "            if not (lines.startswith(\"#\")):\n",
        "                # Split lines in Tabs\n",
        "                line = lines.split(\"\\t\")\n",
        "                \n",
        "                # Check if it has all the informations in the line\n",
        "                if (len(line) == 10):\n",
        "                    # Separate the tokens information\n",
        "                    ind = line[0] # index\n",
        "                    tok = line[1] # token\n",
        "                    pos = line[4] # UPOS-tag\n",
        "                    head = line[6] # Head of the dependency\n",
        "                    dep = line[7] # Dependency relation\n",
        "                    last = line[9] # last column - gets MWE and NoSpaceAfter, for example\n",
        "                \n",
        "                    if \"nmod\" in dep:   # (C)\n",
        "                        fwa.write(\"Sentence: \" + str(sentId) + \" - Token: \" + tok + \" - Index (\" + ind + \") - Head: \" + head + \" Dep: \" + dep + \"\\n\") # (C)\n",
        "                        #fwa.write(\"Sentença: \" + str(sentId) + \" - Token: \" + tok + \" - Index (\" + ind + \") - Pos: \" + pos + \"\\n\")                   # (C)\n",
        "                        count = count + 1\n",
        "                        #print(\"Sentence: \" + str(sentId) + \" - Token: \" + tok + \" - Index (\" + ind + \") - Head: \" + head + \" Dep: \" + dep)            # (C)\n",
        "                        #print(\"Sentença: \" + str(sentId) + \" - Token: \" + tok + \" - Index (\" + ind + \") - Pos: \" + pos)                              # (C)\n",
        "\n",
        "print(\"Amount of matches in the corpus: %d\" %count)\n",
        "print(\"Download the Analysis corpus to get a detailed view of the matches.\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount of matches in the corpus: 9603\n",
            "Download the Analysis corpus to get a detailed view of the matches.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuUFzhmz3s3Y"
      },
      "source": [
        "# close analysis file\n",
        "fwa.close()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNSMZdOxoK30"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS9-RsuzHhs-"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW8UvlFDB_oO"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}